# AITableProject


---

## Описание проекта

**AITableProject** — это интеллектуальная система для автоматического извлечения и обработки табличных данных из различных типов документов с использованием технологий искусственного интеллекта и машинного обучения.

Проект предоставляет веб-интерфейс для загрузки документов (изображения, PDF, Excel, DOCX, TXT) и автоматического извлечения из них структурированных табличных данных в формате Excel или JSON.


## Ключевые возможности

- ✅ **Поддержка множества форматов**: изображения (JPG, PNG), PDF, Excel (XLSX, XLS), DOCX, TXT
- 🤖 **Выбор AI-моделей**: локальные модели (Qwen 3, LLaMA 2) или облачные (OpenAI ChatGPT)
- 🎯 **Точное извлечение таблиц**: сохранение структуры и форматирования
- 🔧 **Предобработка изображений**: автоматическая оптимизация качества для лучшего распознавания
- 📊 **Экспорт результатов**: Excel и JSON форматы
- 🌐 **Удобный веб-интерфейс**: современный UI с drag-and-drop загрузкой
- 🎓 **Обучаемые модели**: возможность дообучения моделей на собственных данных

---

## Архитектура проекта

```
┌──────────────────────────────────────────────┐
│    Веб-интерфейс (Streamlit)                 │
│   (Загрузка файлов, отображение результатов) │
└─────────────────┬────────────────────────────┘
                  │
┌─────────────────▼────────────────────────┐
│       Основной процессор                 │
│    (Определение типа файла)              │
└─────────────────┬────────────────────────┘
                  │
      ┌───────────┼─────────┐
      │           │         │
┌─────▼─────┐ ┌──▼────┐ ┌───▼─────┐
│  Парсеры  │ │Мапперы│ │ Утилиты │
│ (Извлече- │ │(AI/ML)│ │ (Конфиг,│
│   ние)    │ │       │ │ Логи)   │
└───────────┘ └───────┘ └─────────┘
```

---

## Структура проекта

### 📁 Корневая директория

```
AITableProject/
├── src/                      # Исходный код приложения
│   └── learning/
│       └── datasets/         # Датасеты для обучения (Excel файлы)
├── config/                   # Конфигурационные файлы
├── docs/                     # Документация
├── memory-bank/              # База знаний проекта
├── DataScrapeFlow/           # Альтернативный веб-интерфейс (React/Express)
├── inbox/                    # Загруженные файлы (временные)
├── out/                      # Результаты обработки
├── parsing_files/            # Промежуточные данные парсинга (JSON)
├── logs/                     # Логи приложения
├── model_table/              # Справочные таблицы моделей (CSV)
├── tests/                    # Тестовые файлы
└── tmp/                      # Временные файлы
```

### 📦 Основные модули (`src/`)

#### **1. Парсеры (`src/parsers/`)**
Модули для извлечения данных из различных форматов документов:

- **`img_parser.py`** — извлечение таблиц из изображений с помощью PaddleOCR PPStructure
  - Использует технологию OCR для распознавания текста
  - Анализирует структуру таблицы
  - Применяет предобработку изображений для улучшения качества
  
- **`pdf_parser.py`** — парсинг PDF-документов с использованием pdfplumber
  - Извлекает как текстовые, так и табличные данные
  - Поддерживает многостраничные документы
  
- **`excel_parser.py`** — обработка Excel-файлов (XLSX, XLS)
  - Поддержка нескольких листов
  - Сохранение форматирования
  
- **`docx_parser.py`** — извлечение таблиц из документов Word
  - Обработка встроенных таблиц
  - Извлечение изображений с таблицами из DOCX
  
- **`txt_parser.py`** — обработка текстовых файлов и CSV
  - Автоматическое определение разделителей
  - Парсинг структурированного текста
  
- **`openai_parser.py`** — парсинг с использованием OpenAI GPT
  - Облачное решение для сложных случаев
  - Поддержка retry-логики
  
- **`catalogue_parser.py`** — специализированный парсер для каталогов

#### **2. Мапперы (`src/mapper/`)**
Интеграция с AI-моделями для структурирования данных:

- **`mapper.py`** — главный модуль маппинга, координирует работу AI-моделей
  
- **`ask_qwen3.py`** — интеграция с локальной моделью Qwen 3
  - Быстрая обработка на локальном оборудовании
  - Конфиденциальность данных
  
- **`ask_qwen3_so.py`** — Qwen 3 со структурированным выводом (Structured Output)
  - Использует Pydantic для валидации схемы
  - Гарантирует корректный формат JSON
  
- **`ask_qwen2.py`** — поддержка Qwen 2 VL (Vision-Language модель)
  - Мультимодальная обработка текста и изображений
  
- **`ask_llama2.py`** — интеграция с LLaMA 2
  - Альтернативная модель для сравнения результатов

#### **3. Утилиты (`src/utils/`)**
Вспомогательные модули:

- **`config.py`** — централизованное управление конфигурацией
  - Пути к директориям
  - Константы приложения
  - Загрузка переменных окружения
  
- **`logging_config.py`** — настройка системы логирования
  - JSON-конфигурация логов
  - Ротация файлов логов
  - Различные уровни логирования
  
- **`process_files.py`** — оркестратор обработки файлов
  - Определение типа файла
  - Вызов соответствующего парсера
  - Координация работы с AI-моделями
  
- **`preprocess_image.py`** — предобработка изображений (575 строк кода)
  - Коррекция перспективы
  - Улучшение контрастности
  - Удаление шумов
  - Бинаризация
  
- **`image_preprocessor.py`** — дополнительный модуль обработки изображений
  - Работа с YAML-конфигурацией
  - Автоматическая настройка параметров
  
- **`ocr_postprocessor.py`** — постобработка результатов OCR
  - Исправление опечаток
  - Морфологический анализ (pymorphy3)
  - Fuzzy matching для коррекции
  
- **`df_utils.py`** — утилиты для работы с DataFrame (885 строк кода)
  - Семантическое определение заголовков
  - Очистка и валидация данных
  - Экспорт в JSON/Excel
  - **Интеллектуальная реконструкция таблиц из OCR**:
    - Объединение OCR блоков по ячейкам таблицы (PPStructure V3)
    - IoU (Intersection over Union) для точного сопоставления
    - Группировка текстовых блоков по строкам
    - Адаптивная детекция границ столбцов
  - Поддержка полной интеграции с PPStructure V3
  
- **`registry.py`** — система регистрации парсеров
  - Паттерн Registry для динамического выбора парсера

#### **4. Веб-приложение (`src/app/`)**

- **`enhanced_app.py`** — главное веб-приложение на Streamlit
  - Современный UI/UX дизайн
  - Drag-and-drop загрузка файлов
  - Выбор AI-модели
  - Настройки обработки
  - Скачивание результатов
  
- **`templates/`** — HTML-шаблоны для компонентов UI
  - Модульная система шаблонов
  - Компоненты: header, upload card, file list, results display
  
- **`static/styles.css`** — стили для веб-интерфейса
  - Профессиональный дизайн
  - Адаптивная верстка

#### **5. Обучение моделей (`src/learning/`)**

- **`simple_learn_qwen.ipynb`** — Jupyter ноутбук для обучения Qwen
- **`xport_data.py`** — экспорт данных в Excel для обучения
  - Автоматическое создание Excel файлов из JSON
  - Добавление эталонных листов из model_table
  - Автоподстройка ширины столбцов по содержимому
  - Массовая обработка всех JSON файлов
- **`datasets/`** — подготовка датасетов для обучения
  - Конвертация данных
  - Аугментация
  - Подготовка обучающих данных
  - Excel файлы с эталонными данными
- **`qwen-lora-adapters/`** — LoRA адаптеры для дообученной модели
- **`qwen-finetuned/`** — дообученная модель Qwen

### ⚙️ Конфигурация (`config/`)

- **`logging_config.json`** — конфигурация логирования
- **`preprocess_image_config.yaml`** — параметры предобработки изображений
- **`PPSTRUCTURE_CONFIG_GUIDE.md`** — руководство по настройке PaddleOCR

### 📚 Документация (`docs/`)

- **`PPStructureV3_Parameters_Guide.md`** — руководство по параметрам PPStructure V3
- **`Qwen3_Structured_Output_Documentation.md`** — документация по структурированному выводу Qwen 3

---

## Применённые технологические решения

### 1. **Модульная архитектура с паттерном Registry**
- Каждый тип документа обрабатывается специализированным парсером
- Парсеры регистрируются автоматически и выбираются динамически
- Легко добавлять поддержку новых форматов

### 2. **Абстракция AI-моделей**
- Единый интерфейс для различных моделей (Qwen, LLaMA, OpenAI)
- Возможность переключения между локальными и облачными моделями
- Оптимизация выбора модели под задачу

### 3. **Предобработка изображений**
- Многоступенчатая обработка для улучшения качества OCR
- Адаптивные алгоритмы бинаризации
- Коррекция перспективы и геометрических искажений

### 4. **Интеграция с PPStructure V3**
- Полная поддержка результатов распознавания таблиц PPStructure V3
- **Объединение OCR блоков по ячейкам**:
  - Двухэтапная стратегия сопоставления (центр + IoU)
  - Intersection over Union для граничных блоков
  - Адаптивная группировка текстовых строк внутри ячеек
- Умная детекция границ столбцов с помощью density map
- Корректная обработка многострочных ячеек

### 5. **Постобработка OCR**
- Морфологический анализ для русского языка
- Исправление опечаток с помощью fuzzy matching
- Нормализация Unicode-символов

### 6. **Структурированный вывод (Structured Output)**
- Использование Pydantic для валидации схемы данных
- Гарантия получения данных в требуемом формате
- Динамическое создание моделей данных

### 7. **Fine-tuning моделей и подготовка данных**
- Автоматический экспорт данных для обучения (`xport_data.py`)
- Создание Excel файлов с эталонными данными
- Возможность дообучения Qwen на специфичных данных
- Использование LoRA для эффективного обучения
- Сохранение адаптеров для быстрого переключения

### 8. **Streamlit для веб-интерфейса**
- Быстрая разработка UI для data science приложений
- Автоматическая реактивность
- Python-нативный подход

### 9. **Централизованное логирование**
- JSON-конфигурация для гибкой настройки
- Ротация логов по дням
- Различные уровни логирования для debugging

---

## Установка и настройка

### Системные требования

- **Python**: 3.9 или выше
- **ОС**: Windows, Linux, macOS
- **RAM**: минимум 8 GB (рекомендуется 16 GB для локальных моделей)
- **GPU**: опционально, для ускорения работы локальных моделей (CUDA-совместимая)

### Установка зависимостей

#### Основные Python библиотеки

Создайте файл `requirements.txt` с следующим содержимым:

```txt
# Веб-фреймворк
streamlit>=1.28.0

# Обработка данных
pandas>=2.0.0
numpy>=1.24.0
openpyxl>=3.0.0  # для работы с Excel и автоподстройки столбцов

# Обработка изображений
opencv-python>=4.8.0
Pillow>=10.0.0

# OCR и распознавание структуры
paddleocr>=2.7.0
paddlepaddle>=2.5.0  # или paddlepaddle-gpu для GPU

# AI/ML модели
torch>=2.0.0
transformers>=4.35.0
pydantic>=2.0.0
qwen-vl-utils>=0.0.1  # для Qwen2 VL

# Обработка документов
pdfplumber>=0.10.0
python-docx>=1.0.0

# OpenAI API
openai>=1.0.0
tenacity>=8.2.0

# Обработка текста и постобработка
pymorphy3>=1.2.0
rapidfuzz>=3.0.0
ftfy>=6.1.0
regex>=2023.0.0

# Конфигурация и утилиты
python-dotenv>=1.0.0
PyYAML>=6.0.0

# Дополнительные утилиты
matplotlib>=3.7.0  # для визуализации (опционально)
```

#### Установка

1. **Клонируйте репозиторий** (если применимо):
   ```bash
   git clone <repository-url>
   cd AITableProject
   ```

2. **Создайте виртуальное окружение**:
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate
   
   # Linux/macOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Установите зависимости**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Для GPU-ускорения (опционально)**:
   ```bash
   # Замените paddlepaddle на GPU-версию
   pip uninstall paddlepaddle
   pip install paddlepaddle-gpu
   ```

### Настройка переменных окружения

Создайте файл `.env` в корневой директории:

```env
# OpenAI API ключ (если используете облачную модель)
OPENAI_API_KEY=your_openai_api_key_here

# Путь к моделям (опционально, если не используется значение по умолчанию)
MODEL_DIR=./src/learning/qwen-finetuned

# Уровень логирования
LOG_LEVEL=INFO
```

### Настройка моделей

#### Для использования локальных моделей Qwen:

1. Модели автоматически загружаются при первом запуске
2. Или разместите предобученные модели в `src/learning/qwen-finetuned/`
3. LoRA адаптеры должны находиться в `src/learning/qwen-lora-adapters/`

#### Для использования OpenAI:

1. Получите API ключ на https://platform.openai.com/
2. Добавьте ключ в `.env` файл

---

## Запуск приложения

### Запуск веб-интерфейса

```bash
python src/main.py
```

Приложение автоматически:
- Очистит директории `inbox/` и `parsing_files/`
- Настроит логирование
- Запустит Streamlit веб-сервер

После запуска откройте браузер по адресу: **http://localhost:8501**

### Альтернативный запуск Streamlit напрямую

```bash
streamlit run src/app/enhanced_app.py
```

---

## Использование

### Веб-интерфейс

1. **Загрузка файлов**
   - Перетащите файлы в зону загрузки или нажмите для выбора
   - Поддерживаются: JPG, PNG, PDF, XLSX, XLS, DOCX, DOC, TXT, CSV

2. **Выбор настроек**
   - **Модель AI**: выберите локальную (Qwen 3) или облачную (ChatGPT)
   - **Режим обработки**: 
     - "Умное распределение" — детальная категоризация
     - "Упрощенное распределение" — базовая обработка

3. **Обработка**
   - Нажмите "Начать обработку"
   - Дождитесь завершения
   - Скачайте результат в формате Excel

4. **Результаты**
   - Структурированные таблицы в Excel
   - Промежуточные данные в JSON (в `parsing_files/`)
   - Финальный результат в `out/`

### Программный интерфейс

```python
from pathlib import Path
from src.utils.process_files import process_files

# Список файлов для обработки
files = [
    Path("inbox/document1.pdf"),
    Path("inbox/table_image.jpg"),
]

# Обработка с расширенным режимом и локальной моделью
result_path = process_files(
    files,
    extended=True,        # Умное распределение
    remote_model=False    # Локальная модель
)

print(f"Результат сохранён в: {result_path}")
```

### Подготовка данных для обучения

Для экспорта JSON результатов в Excel файлы для обучения:

```bash
python src/learning/xport_data.py
```

Скрипт автоматически:
- Читает все JSON из `parsing_files/`
- Создает Excel файл для каждого JSON
- Добавляет листы с эталонными данными из `model_table/`
- Подстраивает ширину столбцов по содержимому
- Сохраняет результаты в `src/learning/datasets/`

Структура созданного Excel:
- **Лист INPUT**: данные из JSON файла
- **Лист EXTENDED**: расширенная модель из `extended.csv`
- **Лист SIMPLIFIED**: упрощенная модель из `simplified.csv`

---

## DataScrapeFlow (дополнительный модуль)

В проекте также присутствует альтернативный веб-интерфейс на базе **React + Express**:

- **Frontend**: React с TypeScript, Tailwind CSS, Radix UI
- **Backend**: Express.js с TypeScript
- **База данных**: Drizzle ORM с PostgreSQL
- **Функции**: современный UI, управление сессиями, REST API

### Запуск DataScrapeFlow

```bash
cd DataScrapeFlow

# Установка зависимостей
npm install

# Разработка
npm run dev

# Продакшн сборка
npm run build
npm start
```

---

## Логирование

Система логирования настроена через `config/logging_config.json`:

- **`logs/app.log`** — основной лог приложения
- **`logs/daily.log`** — ежедневный лог с ротацией
- **`src/logs/`** — дополнительные логи модулей

Уровни логирования: DEBUG, INFO, WARNING, ERROR, CRITICAL

---

## Структура данных

### Входные форматы
- Изображения: JPG, JPEG, PNG
- Документы: PDF, DOCX, DOC, TXT
- Таблицы: XLSX, XLS, CSV


---


